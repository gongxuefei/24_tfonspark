{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession\\\n",
    ".builder.\\\n",
    "appName(\"python spark sql example\")\\\n",
    ".config(\"spark.some.config.option\",\"some-value\")\\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = spark.read.format(\"libsvm\")\\\n",
    "    .load(\"data/mllib/sample_linear_regression_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LinearRegression(maxIter=10,regParam=0.3,elasticNetParam=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrModel=lr.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSummary=lrModel.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.189077167598475"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingSummary.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre=lrModel.transform(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+--------------------+\n",
      "|              label|            features|          prediction|\n",
      "+-------------------+--------------------+--------------------+\n",
      "| -9.490009878824548|(10,[0,1,2,3,4,5,...| 0.39922280427864854|\n",
      "| 0.2577820163584905|(10,[0,1,2,3,4,5,...|-0.29559741764686487|\n",
      "| -4.438869807456516|(10,[0,1,2,3,4,5,...|  0.7651496483023066|\n",
      "|-19.782762789614537|(10,[0,1,2,3,4,5,...|  0.7839239258929726|\n",
      "| -7.966593841555266|(10,[0,1,2,3,4,5,...|  1.4831466765011345|\n",
      "| -7.896274316726144|(10,[0,1,2,3,4,5,...| -0.9871618140066576|\n",
      "| -8.464803554195287|(10,[0,1,2,3,4,5,...|  1.5395124755034428|\n",
      "| 2.1214592666251364|(10,[0,1,2,3,4,5,...| 0.05906145957465214|\n",
      "| 1.0720117616524107|(10,[0,1,2,3,4,5,...| -2.0397390816430665|\n",
      "|-13.772441561702871|(10,[0,1,2,3,4,5,...|  2.1211666677165093|\n",
      "| -5.082010756207233|(10,[0,1,2,3,4,5,...|-0.04572650153420729|\n",
      "|  7.887786536531237|(10,[0,1,2,3,4,5,...|  1.4045706595369045|\n",
      "| 14.323146365332388|(10,[0,1,2,3,4,5,...|  1.8936490662233862|\n",
      "|-20.057482615789212|(10,[0,1,2,3,4,5,...|  0.2625495742873283|\n",
      "|-0.8995693247765151|(10,[0,1,2,3,4,5,...|  1.1054144970959854|\n",
      "| -19.16829262296376|(10,[0,1,2,3,4,5,...| -1.3003908887799676|\n",
      "|  5.601801561245534|(10,[0,1,2,3,4,5,...| -2.0446543261749612|\n",
      "|-3.2256352187273354|(10,[0,1,2,3,4,5,...|  -0.960287000485595|\n",
      "| 1.5299675726687754|(10,[0,1,2,3,4,5,...|  1.6330567770307318|\n",
      "| -0.250102447941961|(10,[0,1,2,3,4,5,...|  1.1299316224433398|\n",
      "+-------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pre.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import GeneralizedLinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=spark.read.format(\"libsvm\")\\\n",
    "        .load(\"data/mllib/sample_linear_regression_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "glr=GeneralizedLinearRegression(\n",
    "    family=\"gaussian\",\n",
    "    link=\"identity\",\n",
    "    maxIter=10,\n",
    "    regParam=0.3\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=glr.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre=model.transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9.490010</td>\n",
       "      <td>(0.4551273600657362, 0.36644694351969087, -0.3...</td>\n",
       "      <td>1.484349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.257782</td>\n",
       "      <td>(0.8386555657374337, -0.1270180511534269, 0.49...</td>\n",
       "      <td>-0.629450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.438870</td>\n",
       "      <td>(0.5025608135349202, 0.14208069682973434, 0.16...</td>\n",
       "      <td>0.157672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                           features  prediction\n",
       "0 -9.490010  (0.4551273600657362, 0.36644694351969087, -0.3...    1.484349\n",
       "1  0.257782  (0.8386555657374337, -0.1270180511534269, 0.49...   -0.629450\n",
       "2 -4.438870  (0.5025608135349202, 0.14208069682973434, 0.16...    0.157672"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre.toPandas().head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7950428434287478,\n",
       " 0.8049713176546897,\n",
       " 0.7975916824772489,\n",
       " 0.8312649247659919,\n",
       " 0.7945436200517938,\n",
       " 0.8118992572197593,\n",
       " 0.7919506385542777,\n",
       " 0.7973378214726764,\n",
       " 0.8300714999626418,\n",
       " 0.7771333489686802,\n",
       " 0.463930109648428]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.coefficientStandardErrors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=spark.read.format(\"libsvm\").load(\"data/mllib/sample_libsvm_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData,testData)=data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=DecisionTreeRegressor(featuresCol=\"indexedFeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[featureIndexer, dt])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------------+\n",
      "|prediction|label|            features|\n",
      "+----------+-----+--------------------+\n",
      "|       0.0|  0.0|(692,[95,96,97,12...|\n",
      "|       0.0|  0.0|(692,[100,101,102...|\n",
      "|       0.0|  0.0|(692,[121,122,123...|\n",
      "|       0.0|  0.0|(692,[122,123,124...|\n",
      "|       0.0|  0.0|(692,[124,125,126...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"prediction\", \"label\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse=evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16666666666666666"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=spark.read.format(\"libsvm\").load(\"data/mllib/sample_libsvm_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureIndexer=VectorIndexer(\n",
    "                inputCol=\"features\",\n",
    "                outputCol='indexedFeatures',\n",
    "                maxCategories=4).fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData,testData)=data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestRegressor(featuresCol=\"indexedFeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline=Pipeline(stages=[featureIndexer,rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------------+\n",
      "|prediction|label|            features|\n",
      "+----------+-----+--------------------+\n",
      "|       0.0|  0.0|(692,[123,124,125...|\n",
      "|       0.0|  0.0|(692,[124,125,126...|\n",
      "|       0.0|  0.0|(692,[124,125,126...|\n",
      "|       0.0|  0.0|(692,[126,127,128...|\n",
      "|       0.0|  0.0|(692,[126,127,128...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"prediction\",\"label\",\"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator=RegressionEvaluator(\n",
    "            labelCol=\"label\",\n",
    "            predictionCol=\"prediction\",\n",
    "            metricName=\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse=evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06475761258027332"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient-boosted tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.format(\"libsvm\").load(\"data/mllib/sample_libsvm_data.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData,testData)=data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt=GBTRegressor(featuresCol=\"indexedFeatures\",maxIter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline=Pipeline(stages=[featureIndexer,gbt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|label|\n",
      "+----------+-----+\n",
      "|       1.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       1.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"prediction\",\"label\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator=RegressionEvaluator(\n",
    "        labelCol=\"label\",\n",
    "        predictionCol=\"prediction\",\n",
    "        metricName=\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse=evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26261286571944514"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Survival regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import AFTSurvivalRegression\n",
    "from pyspark.ml.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = spark.createDataFrame([\n",
    "    (1.218, 1.0, Vectors.dense(1.560, -0.605)),\n",
    "    (2.949, 0.0, Vectors.dense(0.346, 2.158)),\n",
    "    (3.627, 0.0, Vectors.dense(1.380, 0.231)),\n",
    "    (0.273, 1.0, Vectors.dense(0.520, 1.151)),\n",
    "    (4.199, 0.0, Vectors.dense(0.795, -0.226))], [\"label\", \"censor\", \"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+--------------+\n",
      "|label|censor|      features|\n",
      "+-----+------+--------------+\n",
      "|1.218|   1.0| [1.56,-0.605]|\n",
      "|2.949|   0.0| [0.346,2.158]|\n",
      "|3.627|   0.0|  [1.38,0.231]|\n",
      "|0.273|   1.0|  [0.52,1.151]|\n",
      "|4.199|   0.0|[0.795,-0.226]|\n",
      "+-----+------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantileProbabilities=[0.3,0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "aft=AFTSurvivalRegression(quantileProbabilities=quantileProbabilities,\n",
    "                         quantilesCol=\"quantiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=aft.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+--------------+------------------+---------------------------------------+\n",
      "|label|censor|features      |prediction        |quantiles                              |\n",
      "+-----+------+--------------+------------------+---------------------------------------+\n",
      "|1.218|1.0   |[1.56,-0.605] |5.718979487634989 |[1.1603238947151626,4.995456010274754] |\n",
      "|2.949|0.0   |[0.346,2.158] |18.076521181495476|[3.6675458454717678,15.78961186627775] |\n",
      "|3.627|0.0   |[1.38,0.231]  |7.381861804239103 |[1.497706130519084,6.447962612338967]  |\n",
      "|0.273|1.0   |[0.52,1.151]  |13.577612501425325|[2.7547621481506934,11.859872224069736]|\n",
      "|4.199|0.0   |[0.795,-0.226]|9.013097744073866 |[1.828667632129776,7.872826505878401]  |\n",
      "+-----+------+--------------+------------------+---------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.transform(training).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isotonic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import IsotonicRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = spark.read.format(\"libsvm\")\\\n",
    "    .load(\"data/mllib/sample_isotonic_regression_libsvm_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=IsotonicRegression().fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-------------------+\n",
      "|     label|      features|         prediction|\n",
      "+----------+--------------+-------------------+\n",
      "|0.24579296|(1,[0],[0.01])|0.15715271294117644|\n",
      "|0.28505864|(1,[0],[0.02])|0.15715271294117644|\n",
      "|0.31208567|(1,[0],[0.03])|0.15715271294117644|\n",
      "|0.35900051|(1,[0],[0.04])|0.15715271294117644|\n",
      "|0.35747068|(1,[0],[0.05])|0.15715271294117644|\n",
      "|0.16675166|(1,[0],[0.06])|0.15715271294117644|\n",
      "|0.17491076|(1,[0],[0.07])|0.15715271294117644|\n",
      "| 0.0418154|(1,[0],[0.08])|0.15715271294117644|\n",
      "|0.04793473|(1,[0],[0.09])|0.15715271294117644|\n",
      "|0.03926568| (1,[0],[0.1])|0.15715271294117644|\n",
      "|0.12952575|(1,[0],[0.11])|0.15715271294117644|\n",
      "|       0.0|(1,[0],[0.12])|0.15715271294117644|\n",
      "|0.01376849|(1,[0],[0.13])|0.15715271294117644|\n",
      "|0.13105558|(1,[0],[0.14])|0.15715271294117644|\n",
      "|0.08873024|(1,[0],[0.15])|0.15715271294117644|\n",
      "|0.12595614|(1,[0],[0.16])|0.15715271294117644|\n",
      "|0.15247323|(1,[0],[0.17])|0.15715271294117644|\n",
      "|0.25956145|(1,[0],[0.18])|        0.189138196|\n",
      "|0.20040796|(1,[0],[0.19])|        0.189138196|\n",
      "|0.19581846| (1,[0],[0.2])|        0.189138196|\n",
      "+----------+--------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.transform(dataset).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
